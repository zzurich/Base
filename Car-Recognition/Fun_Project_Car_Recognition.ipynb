{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fun Project - Car Recognition",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AlzIlBsScJJ_"
      },
      "source": [
        "# Using Pre-Trained Models Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nTirVS4FWaPx"
      },
      "source": [
        "In this project we will import a pre-existing model that recognizes objects and use the model to identify those objects in a video. We'll edit the video to draw boxes around the identified object and then reassemble the video so that the boxes are shown around objects in the video."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_yACB56w2JVk"
      },
      "source": [
        "## Team\n",
        "\n",
        "*   *Prashamsa Rimal*\n",
        "*   *Christine Zhu*\n",
        "*   *Rosemary Austin*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qc64hUGVaInl",
        "colab_type": "text"
      },
      "source": [
        "# **1. Obtain a video file from Pixabay to use for classification.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ivTzfzQN5jDk",
        "colab": {}
      },
      "source": [
        "#This is loading in the video file\n",
        "\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "cars_video = cv.VideoCapture('cars.mp4')\n",
        "\n",
        "height = int(cars_video.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
        "width = int(cars_video.get(cv.CAP_PROP_FRAME_WIDTH))\n",
        "fps = cars_video.get(cv.CAP_PROP_FPS)\n",
        "total_frames = int(cars_video.get(cv.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "cars_video.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrN9VfMtZmiR",
        "colab_type": "text"
      },
      "source": [
        "# **2. Obtain the pre-trained model from the TensorFlow Zoo.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlThBHZZQnGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This is uploading the model \n",
        "\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
        "file_name = 'ssd_mobilenet_v1_coco_2018_01_28.tar.gz'\n",
        "\n",
        "url = base_url + file_name\n",
        "\n",
        "urllib.request.urlretrieve(url, file_name)\n",
        "\n",
        "os.listdir()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdlnKX3kcP7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract the Model Data\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "dir_name = file_name[0:-len('.tar.gz')]\n",
        "if os.path.exists(dir_name):\n",
        "  shutil.rmtree(dir_name) \n",
        "\n",
        "tarfile.open(file_name, 'r:gz').extractall('./')\n",
        "\n",
        "os.listdir(dir_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZs8rDZVZydA",
        "colab_type": "text"
      },
      "source": [
        "# **3. Load the pre-trained model into a TensorFlow object.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi0VWpB0cTBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading the graph\n",
        "frozen_graph = os.path.join(dir_name, 'frozen_inference_graph.pb')\n",
        "\n",
        "with tf.gfile.FastGFile(frozen_graph,'rb') as f:\n",
        "  graph_def = tf.GraphDef()\n",
        "  graph_def.ParseFromString(f.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPOPLoyucTq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs = (\n",
        "    'num_detections',\n",
        "    'detection_classes',\n",
        "    'detection_scores',\n",
        "    'detection_boxes',\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr3aYc7xv9Jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This resizes it in readable form\n",
        "def frame_fix(image):\n",
        "  frame = cv.resize(image, (300, 300))\n",
        "  return frame\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7BhKfOJv_Y3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import the dataset library\n",
        "open_new = open(\"labels.txt\", \"r\")\n",
        "labels={}\n",
        "for x in open_new:\n",
        "  key,_,value=x.partition(':')\n",
        "  value,_,_=value.partition('\\n')\n",
        "  labels[key]=value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhLtEjptxDV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtvKk-n7yJWu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing the loading bar\n",
        "from tqdm import tqdm_notebook as tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeWke_z5iD0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cars_video = cv.VideoCapture('cars.mp4')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4exkWToaV_L",
        "colab_type": "text"
      },
      "source": [
        "# **4. Process the video frame-by-frame creating a modified output video.**\n",
        "# **5. Apply a classification model to an image.**\n",
        "# **6. Draw a bounding box around classified objects in each image.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsRXqbP3wHt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 4. Process the car video frame-by-frame to create a modified out video\n",
        "\n",
        "total_frames = int(cars_video.get(cv.CAP_PROP_FRAME_COUNT))\n",
        "fourcc = cv.VideoWriter_fourcc(*'mp4v')\n",
        "output_video = cv.VideoWriter('Cars-short.mp4', fourcc, fps, (300,300))\n",
        "\n",
        "#looping through each frame\n",
        "for current_frame in tqdm(range(0, total_frames,30)): #Capture a frame for every 50 frames\n",
        "  cars_video.set(cv.CAP_PROP_POS_FRAMES, current_frame)\n",
        "  ret, frame = cars_video.read()  \n",
        "  frame=cv.resize(frame,(300,300)) #resize the frame to 300*300\n",
        "  if not ret:\n",
        "    raise Exception(f'Problem reading frame {current_frame} from video')\n",
        "  image = [frame] #image into a list \n",
        "  \n",
        "  #5. starts tensor flow sess to create the graph \n",
        "  with tf.Session() as sess:\n",
        "    sess.graph.as_default()\n",
        "    tf.import_graph_def(graph_def, name='')\n",
        "\n",
        "    detections = sess.run(\n",
        "        [sess.graph.get_tensor_by_name(f'{op}:0') for op in outputs],\n",
        "        feed_dict={ 'image_tensor:0': image })\n",
        "    \n",
        "    # 6. Draw a bounding box around classified objects in each image  \n",
        "    height,width,colour = frame.shape\n",
        "    for det in range(int(detections[0][0])):\n",
        "      left = detections[3][0][det][1] *width\n",
        "      top = detections[3][0][det][0] * height\n",
        "      right = detections[3][0][det][3] *width\n",
        "      bottom = detections[3][0][det][2] *height\n",
        "      frame = cv.rectangle(frame,(int(left),int(top)),(int(right),int(bottom)),[0,255,0],2)\n",
        "      label = labels[str(int(detections[1][0][det]))]\n",
        "      frame = cv.putText(frame, label , (int(left),int(top)), cv.FONT_HERSHEY_SIMPLEX,1,[0,255,0],2)\n",
        "    \n",
        "    #create the video   \n",
        "    output_video.write(frame)\n",
        "    \n",
        "#release the video\n",
        "output_video.release()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}